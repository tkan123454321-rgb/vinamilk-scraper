from IPython.display import display
from vnstock import *
import pandas as pd
import time
import os
import shutil
from sqlalchemy import *
from urllib.parse import quote_plus
from stock_processed_sql import *
import sys
import json
import traceback


# Database connection setup
db_user = 'tkan'
db_password = 'Maihainganha@1'
db_host = 'localhost'  
db_port = '5432'       
db_name = 'finance_db' 
password = quote_plus(db_password) # Encode password
connection_str = f'postgresql://{db_user}:{password}@{db_host}:{db_port}/{db_name}' # Connection string
engine = create_engine(connection_str) # Create engine
inspector = inspect(engine) # Create inspector

def update_companies_list(engine):
    listing = Listing(source='VCI')

    # c·∫≠p nh·∫≠t b·∫£ng company_list
    df_listing = listing.symbols_by_industries()
    blacklist =['CK','NH','BH'] # lo·∫°i b·ªè c·ªï phi·∫øu ch·ª©ng kho√°n, ng√¢n h√†ng, b·∫£o hi·ªÉm
    df_listing = df_listing[~df_listing['com_type_code'].isin(blacklist)] # lo·∫°i b·ªè c·ªï phi·∫øu trong blacklist
    hose_list = listing.symbols_by_group('HOSE').astype(str).str.upper().str.strip().to_list() # danh s√°ch c·ªï phi·∫øu s√†n HOSE
    hnx_list = listing.symbols_by_group('HNX').astype(str).str.upper().str.strip().to_list() # danh s√°ch c·ªï phi·∫øu s√†n HNX
    white_list = set(hose_list + hnx_list) # t·∫≠p h·ª£p c·ªï phi·∫øu s√†n HOSE v√† HNX
    df_listing = df_listing[df_listing['symbol'].astype(str).str.upper().str.strip().isin(white_list)] # ch·ªâ gi·ªØ l·∫°i c·ªï phi·∫øu trong white_list
    df_listing = df_listing.drop(['icb_name2','icb_name4','com_type_code','icb_code1','icb_code2','icb_code3','icb_code4'], axis=1)
    df_listing = df_listing.rename(columns={
        'symbol': 'Ticker',
        'organ_name': 'Company Name',
        'icb_name3': 'Industry Name',
    })

    df_listing.to_sql('temp_table', engine, schema = 'raw', if_exists='replace', index=False)  
    if inspector.has_table('companies_list', schema='analysis_data'):
        query = """
        INSERT INTO analysis_data.companies_list ("Ticker", "Company Name", "Industry Name")
        SELECT "Ticker", "Company Name", "Industry Name"
        FROM raw.temp_table
        ON CONFLICT ("Ticker")
        DO UPDATE SET
            "Company Name" = EXCLUDED."Company Name",
            "Industry Name" = EXCLUDED."Industry Name";
        """ # th√™m d·ªØ li·ªáu v√†o b·∫£ng companies_list, n·∫øu ƒë√£ t·ªìn t·∫°i th√¨ c·∫≠p nh·∫≠t l·∫°i th√¥ng tin

        drop_temp_table = "DROP TABLE IF EXISTS raw.temp_table;" # x√≥a b·∫£ng t·∫°m temp_table

        with engine.connect() as conn:
            conn.execute(text(query)) # Execute DML to insert/update data
            conn.execute(text(drop_temp_table)) # Drop temp_table
            conn.commit()

# H√†m c·∫≠p nh·∫≠t d·ªØ li·ªáu b·∫£ng balance_sheet trong schema raw
def update_balance_raw(engine):
    #truy·ªÅn d·ªØ li·ªáu balance sheet
    failed_tickers_balance =[]
    balance_tickers = set()
    df_tickers = pd.read_sql('SELECT "Ticker" FROM analysis_data.companies_list', engine)
    ticker_list = set(df_tickers['Ticker'].str.strip())
    if inspector.has_table('balance_sheet', schema='raw'):
        df_all_balance = pd.read_sql('SELECT "Ticker" FROM raw.balance_sheet', engine)
        balance_tickers = set(df_all_balance['Ticker'].str.strip())
    missing_tickers = set(ticker_list - balance_tickers)
    print(len(missing_tickers))

    for i, ticker in enumerate(missing_tickers):
        try: 
            df_balancesheet = balance_sheet(ticker)
            df_balancesheet = df_balancesheet.set_index(df_balancesheet.columns[0])
            df_balancesheet.loc['Ticker'] = ticker
            df_balancesheet = df_balancesheet.T
            df_balancesheet.columns.name = None
            df_balancesheet.index.name = 'year'
            df_balancesheet = df_balancesheet.reset_index()
            if 'Ticker' in df_balancesheet.columns and 'year' in df_balancesheet.columns: # ƒë·∫£m b·∫£o kh√¥ng c√≥ d·ªØ li·ªáu tr√πng l·∫∑p
                df_balancesheet = df_balancesheet.drop_duplicates(subset= ['Ticker', 'year'], keep='last')
            if inspector.has_table('balance_sheet'):
                with engine.connect() as conn:
                    conn.execute(text(f"DELETE FROM raw.balance_sheet WHERE \"Ticker\" = '{ticker}'"))
                    conn.commit()
            df_balancesheet.to_sql('balance_sheet', engine, schema='raw', if_exists='append', index=False)
            print(f"ƒê√£ x·ª≠ l√Ω xong ticker {i+1}/{len(missing_tickers)}: {ticker}")
        except Exception as e:
            print(f"L·ªói v·ªõi ticker {ticker}: {e}")
        time.sleep(3)  # Th√™m ƒë·ªô tr·ªÖ 5 gi√¢y gi·ªØa c√°c l·∫ßn l·∫∑p
        
    print(pd.DataFrame(failed_tickers_balance))


#truy·ªÅn d·ªØ li·ªáu income statement raw
def update_income_raw(engine):
    df_tickers = pd.read_sql('SELECT "Ticker" FROM analysis_data.companies_list', engine)
    ticker_list = set(df_tickers['Ticker'].str.strip())
    income_tickers = set()
    if inspector.has_table('income_statement', schema='raw'):
        df_all_income = pd.read_sql('SELECT "Ticker" FROM raw.income_statement', engine)
        income_tickers = set(df_all_income['Ticker'].str.strip())
    missing_tickers = set(ticker_list - income_tickers)
    print(missing_tickers), print(len(missing_tickers))
        
    failed_tickers_income =[]
    for i, ticker in enumerate(missing_tickers):
        try: 
            df_ic = income_statement(ticker)
            df_ic = df_ic.set_index(ticker)
            df_ic.loc['Ticker'] = ticker 
            df_ic = df_ic.T
            df_ic.columns.name = None
            df_ic.index.name = 'year'
            df_ic = df_ic.reset_index()
            if 'Ticker' in df_ic.columns and 'year' in df_ic.columns: # ƒë·∫£m b·∫£o kh√¥ng c√≥ d·ªØ li·ªáu tr√πng l·∫∑p
                df_ic = df_ic.drop_duplicates(subset= ['Ticker', 'year'], keep='last')
            if inspector.has_table('income_statement'):
                with engine.connect() as conn:
                    conn.execute(text(f"DELETE FROM raw.income_statement WHERE \"Ticker\" = '{ticker}'"))
                    conn.commit()
            df_ic.to_sql('income_statement', engine, schema='raw', if_exists='append', index=False)
            print(f"ƒê√£ x·ª≠ l√Ω xong ticker {i+1}/{len(missing_tickers)}: {ticker}")

        except Exception as e:
            print(f"L·ªói v·ªõi ticker {ticker}: {e}")
            failed_tickers_income.append({'ticker': ticker, 'error': str(e)})
        time.sleep(3)

    print(f"t√¨m th·∫•y {len(failed_tickers_income)} ticker(s) l·ªói")


# H√†m c·∫≠p nh·∫≠t d·ªØ li·ªáu b·∫£ng cash_flow trong schema raw
def update_cashflow_raw(engine):
    # truy·ªÅn d·ªØ li·ªáu cash flow
    indirect_tickers = set()
    direct_tickers = set()
    df_tickers = pd.read_sql('SELECT "Ticker" FROM analysis_data.companies_list', engine)
    ticker_list = set(df_tickers['Ticker'].str.strip())
    if inspector.has_table('cash_flow_indirect', schema='raw'):
        df_all_indirect = pd.read_sql('SELECT "Ticker" FROM raw.cash_flow_indirect', engine)
        indirect_tickers = set(df_all_indirect['Ticker'].str.strip())
    if inspector.has_table('cash_flow_direct', schema='raw'):
        df_all_direct = pd.read_sql('SELECT "Ticker" FROM raw.cash_flow_direct', engine)
        direct_tickers = set(df_all_direct['Ticker'].str.strip())
    missing_tickers = list(ticker_list - (indirect_tickers | direct_tickers))
    tickers_failed_cash_flow = []
    print(missing_tickers)

    for i, ticker in enumerate(missing_tickers):
        try:
            target_table = 'unknown'
            df_cf = cash_flow(ticker)
            df_cf = df_cf.set_index(df_cf.columns[0])
            df_cf.loc['Ticker'] = ticker
            df_cf = df_cf.T
            df_cf.columns.name = None
            df_cf.index.name = 'year'
            df_cf = df_cf.reset_index()
            df_cf.columns = df_cf.columns.str.strip()
            if 'Ticker' in df_cf.columns and 'year' in df_cf.columns: # ƒë·∫£m b·∫£o kh√¥ng c√≥ d·ªØ li·ªáu tr√πng l·∫∑p
                df_cf = df_cf.drop_duplicates(subset= ['Ticker', 'year'], keep='last')
            if '1. Ti·ªÅn thu t·ª´ b√°n h√†ng, cung c·∫•p d·ªãch v·ª• v√† doanh thu kh√°c' in df_cf.columns:
                target_table = 'cash_flow_direct'
            elif '2. ƒêi·ªÅu ch·ªânh cho c√°c kho·∫£n' in df_cf.columns:
                target_table = 'cash_flow_indirect'
            if inspector.has_table(target_table, schema='raw'):
                with engine.connect() as conn:
                    conn.execute(text(f"DELETE FROM raw.{target_table} WHERE \"Ticker\" = '{ticker}'"))
                    conn.commit()
            df_cf.to_sql(target_table, engine, schema='raw', if_exists='append', index=False)
            print(f"ƒê√£ x·ª≠ l√Ω xong ticker {i+1}/{len(missing_tickers)}: {ticker} v√†o b·∫£ng {target_table}")
        except Exception as e:
            print(f"L·ªói v·ªõi ticker {ticker}: {e}")
            tickers_failed_cash_flow.append({'ticker': ticker, 'error': str(e)})
        time.sleep(1)  # Th√™m ƒë·ªô tr·ªÖ 5 gi√¢y gi·ªØa c√°c l·∫ßn l·∫∑p

    print(f" T√¨m th·∫•y {len(tickers_failed_cash_flow)} ticker(s) l·ªói")

# H√†m c·∫≠p nh·∫≠t d·ªØ li·ªáu b·∫£ng financial_ratio trong schema raw
def update_ratio_raw(engine, inspector):
    failed_tickers = []
    ratio_ticker = set()
    df_tickers = pd.read_sql('SELECT "Ticker" FROM analysis_data.companies_list', engine)
    ticker_list = set(df_tickers['Ticker'].str.strip())
    if inspector.has_table('financial_ratio', schema='raw'):
        df_all_ratio = pd.read_sql('SELECT "Ticker" FROM raw.financial_ratio', engine)
        ratio_ticker = set(df_all_ratio['Ticker'].str.strip())
    missing_tickers = set(ticker_list - ratio_ticker)
    print(len(missing_tickers))
    column_mapping = {
        "Nh√≥m ch·ªâ s·ªë ƒê·ªãnh gi√°": "Valuation Ratios",
        "EPS": "eps",
        "BVPS": "bvps",
        "P/E": "pe",
        "P/B": "pb",
        "P/S": "ps",
        "EV/EBITDA": "ev_ebitda",
        "Nh√≥m ch·ªâ s·ªë Sinh l·ª£i": "Profitability Ratios",
        "Bi√™n EBIT (%)": "ebit_margin",
        "Bi√™n l·ª£i nhu·∫≠n g·ªôp (%)": "gross_margin",
        "Bi√™n l·ª£i nhu·∫≠n r√≤ng (%)": "net_margin",
        "T·ª∑ su·∫•t sinh l·ª£i tr√™n t·ªïng t√†i s·∫£n b√¨nh qu√¢n (ROAA) (%)": "roaa",
        "T·ª∑ su·∫•t sinh l·ª£i tr√™n v·ªën ch·ªß s·ªü h·ªØu b√¨nh qu√¢n (ROEA) (%)": "roea",
        "T·ª∑ su·∫•t sinh l·ª£i tr√™n v·ªën d√†i h·∫°n b√¨nh qu√¢n (ROCE) (%)": "roce",
        "Nh√≥m ch·ªâ s·ªë TƒÉng tr∆∞·ªüng": "Growth Ratios",
        "TƒÉng tr∆∞·ªüng doanh thu thu·∫ßn (%)": "revenue_growth",
        "TƒÉng tr∆∞·ªüng l·ª£i nhu·∫≠n sau thu·∫ø (%)": "net_income_growth",
        "Nh√≥m ch·ªâ s·ªë Thanh kho·∫£n": "Liquidity Ratios",
        "T·ª∑ s·ªë thanh to√°n hi·ªán h√†nh (ng·∫Øn h·∫°n)": "current_ratio",
        "Ch·ªâ s·ªë thanh to√°n nhanh": "quick_ratio",
        "Kh·∫£ nƒÉng chi tr·∫£ l√£i vay": "interest_coverage_ratio",
        "Nh√≥m ch·ªâ s·ªë Hi·ªáu qu·∫£ ho·∫°t ƒë·ªông": "Efficiency Ratios",
        "Th·ªùi gian thu ti·ªÅn kh√°ch h√†ng b√¨nh qu√¢n (ng√†y)": "days_sales_outstanding",
        "Th·ªùi gian t·ªìn kho b√¨nh qu√¢n (ng√†y)": "days_inventory_outstanding",
        "V√≤ng quay h√†ng t·ªìn kho": "inventory_turnover",
        "V√≤ng quay t·ªïng t√†i s·∫£n": "total_asset_turnover",
        "S·ªë ng√†y tr·∫£ cho nh√† cung c·∫•p (ng√†y)": "days_payable_outstanding",
        "V√≤ng quay tr·∫£ cho nh√† cung c·∫•p": "payable_turnover",
        "Chu k·ª≥ chuy·ªÉn ƒë·ªïi ti·ªÅn m·∫∑t (CCC) (ng√†y)": "cash_conversion_cycle",
        "Nh√≥m ch·ªâ s·ªë ƒê√≤n b·∫©y t√†i ch√≠nh": "Financial Leverage Ratios",
        "T·ª∑ s·ªë N·ª£ vay tr√™n V·ªën ch·ªß s·ªü h·ªØu (%)": "debt_to_equity_ratio",
        "T·ª∑ s·ªë N·ª£ vay tr√™n T·ªïng t√†i s·∫£n (%)": "debt_to_assets_ratio",
        "Nh√≥m ch·ªâ s·ªë D√≤ng ti·ªÅn": "Cash Flow Ratios",
        "T·ª∑ s·ªë d√≤ng ti·ªÅn HƒêKD tr√™n doanh thu thu·∫ßn (%)": "operating_cash_flow_to_revenue_ratio",
        "D√≤ng ti·ªÅn t·ª´ HƒêKD tr√™n T·ªïng t√†i s·∫£n (%)": "operating_cash_flow_to_total_assets_ratio",
        "D√≤ng ti·ªÅn t·ª´ HƒêKD tr√™n V·ªën ch·ªß s·ªü h·ªØu (%)": "operating_cash_flow_to_equity_ratio",
        "D√≤ng ti·ªÅn t·ª´ HƒêKD tr√™n m·ªói c·ªï ph·∫ßn": "operating_cash_flow_per_share"
    }
    for i, ticker in enumerate(missing_tickers):
        try: 
            df_ratio = ratio_calculation(ticker)
            df_ratio = df_ratio.set_index('Ch·ªâ s·ªë')
            df_ratio.loc['Ticker'] = ticker
            df_ratio = df_ratio.T
            df_ratio.index.name = 'year'
            df_ratio.columns.name = None
            df_ratio = df_ratio.reset_index()
            if 'Ticker' in df_ratio.columns and 'year' in df_ratio.columns:
                df_ratio = df_ratio.drop_duplicates(subset= ['Ticker', 'year'], keep='last')
            df_ratio = df_ratio.rename(columns=column_mapping)
            if inspector.has_table('financial_ratio'):
                with engine.connect() as conn:
                    conn.execute(text(f"DELETE FROM raw.financial_ratio WHERE TRIM(\"Ticker\") = '{ticker}'"))
                    conn.commit()
            
            df_ratio.to_sql('financial_ratio', engine ,schema = 'raw', if_exists='append', index=False)
            print(f"ƒê√£ x·ª≠ l√Ω xong ticker {i+1}/{len(missing_tickers)}: {ticker}")
        except KeyboardInterrupt:
            print("Qu√° tr√¨nh b·ªã gi√°n ƒëo·∫°n b·ªüi ng∆∞·ªùi d√πng.")
            sys.exit(0)
        except Exception as e:
            print(f"L·ªói v·ªõi ticker {ticker}: {e}")
            traceback.print_exc()
            failed_tickers.append({'ticker': ticker, 'error': str(e)})
        time.sleep(3)  # Th√™m ƒë·ªô tr·ªÖ 2 gi√¢y gi·ªØa c√°c l·∫ßn l·∫∑p

    display(pd.DataFrame(failed_tickers))

    if os.path.exists('data_processed'):
        shutil.rmtree('data_processed')

    if os.path.exists('data_raw'):
        shutil.rmtree('data_raw')

        
        
def insert_ic_quarter(engine): # H√†m ch√®n d·ªØ li·ªáu b√°o c√°o t√†i ch√≠nh qu√Ω v√†o b·∫£ng ic_quarter trong schema raw
    quarter_tickers = set() # T·∫°o set r·ªóng tr∆∞·ªõc
    df_tickers = pd.read_sql('SELECT "Ticker" FROM analysis_data.companies_list', engine) # L·∫•y danh s√°ch ticker t·ª´ b·∫£ng companies_list
    ticker_list = set(df_tickers['Ticker'].str.strip()) # Chuy·ªÉn danh s√°ch ticker th√†nh set ƒë·ªÉ d·ªÖ d√†ng so s√°nh
     # L·∫•y danh s√°ch ticker ƒë√£ c√≥ trong b·∫£ng ic_quarter
    if inspector.has_table('ic_quarter', schema='raw'):
        df_all_quarter_ic = pd.read_sql('SELECT "Ticker" FROM raw.ic_quarter', engine)
        quarter_tickers = set(df_all_quarter_ic['Ticker'].str.strip()) # Chuy·ªÉn danh s√°ch ticker ƒë√£ c√≥ th√†nh set
    missing_tickers = set(ticker_list - quarter_tickers) # T√¨m c√°c ticker ch∆∞a c√≥ trong b·∫£ng ic_quarter
    print(len(missing_tickers))

    for i,ticker in enumerate(missing_tickers): # L·∫∑p qua t·ª´ng ticker ch∆∞a c√≥
        try:
            print(f'Processing {i+1}/{len(missing_tickers)}: {ticker}')
            co_phieu = ticker
            start = 2020
            end = 2025
            years = range(end, start-1, -1)
            quarters = [4,3,2,1]
            auth_token = 'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IkdYdExONzViZlZQakdvNERWdjV4QkRITHpnSSIsImtpZCI6IkdYdExONzViZlZQakdvNERWdjV4QkRITHpnSSJ9.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmZpcmVhbnQudm4iLCJhdWQiOiJodHRwczovL2FjY291bnRzLmZpcmVhbnQudm4vcmVzb3VyY2VzIiwiZXhwIjoxODg5NjIyNTMwLCJuYmYiOjE1ODk2MjI1MzAsImNsaWVudF9pZCI6ImZpcmVhbnQudHJhZGVzdGF0aW9uIiwic2NvcGUiOlsiYWNhZGVteS1yZWFkIiwiYWNhZGVteS13cml0ZSIsImFjY291bnRzLXJlYWQiLCJhY2NvdW50cy13cml0ZSIsImJsb2ctcmVhZCIsImNvbXBhbmllcy1yZWFkIiwiZmluYW5jZS1yZWFkIiwiaW5kaXZpZHVhbHMtcmVhZCIsImludmVzdG9wZWRpYS1yZWFkIiwib3JkZXJzLXJlYWQiLCJvcmRlcnMtd3JpdGUiLCJwb3N0cy1yZWFkIiwicG9zdHMtd3JpdGUiLCJzZWFyY2giLCJzeW1ib2xzLXJlYWQiLCJ1c2VyLWRhdGEtcmVhZCIsInVzZXItZGF0YS13cml0ZSIsInVzZXJzLXJlYWQiXSwianRpIjoiMjYxYTZhYWQ2MTQ5Njk1ZmJiYzcwODM5MjM0Njc1NWQifQ.dA5-HVzWv-BRfEiAd24uNBiBxASO-PAyWeWESovZm_hj4aXMAZA1-bWNZeXt88dqogo18AwpDQ-h6gefLPdZSFrG5umC1dVWaeYvUnGm62g4XS29fj6p01dhKNNqrsu5KrhnhdnKYVv9VdmbmqDfWR8wDgglk5cJFqalzq6dJWJInFQEPmUs9BW_Zs8tQDn-i5r4tYq2U8vCdqptXoM7YgPllXaPVDeccC9QNu2Xlp9WUvoROzoQXg25lFub1IYkTrM66gJ6t9fJRZToewCt495WNEOQFa_rwLCZ1QwzvL0iYkONHS_jZ0BOhBCdW9dWSawD6iF1SIQaFROvMDH1rg'
            user = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'
            headers = { 'Authorization': auth_token,
                        'User-Agent': user}
            query = text("""
                        INSERT INTO raw.ic_quarter ("Ticker", "Year", "Quarter", "data")
                        VALUES (:ticker, :year, :quarter, :data)
                        ON CONFLICT ("Ticker", "Year", "Quarter") 
                        DO UPDATE SET 
                        "data" = EXCLUDED."data",
                        "insert at" = CURRENT_TIMESTAMP;
                        
            """) # C√¢u l·ªánh ch√®n d·ªØ li·ªáu v·ªõi x·ª≠ l√Ω tr√πng l·∫∑p
            with engine.connect() as conn:
                transaction = conn.begin()
                if inspector.has_table('ic_quarter', schema='raw'): # Ki·ªÉm tra n·∫øu b·∫£ng ic_quarter ƒë√£ t·ªìn t·∫°i
                    try:
                        for y in years: # t·∫°o danh s√°ch url t·ª± ƒë·ªông t·ª´ nƒÉm end ƒë·∫øn start
                            print(f'Year: {y}')
                            for q in quarters:
                                print(f'  Quarter: {q}')
                                url = f'https://restv2.fireant.vn/symbols/{co_phieu}/full-financial-reports?type=2&year={y}&quarter={q}&limit=1' # URL API
                                params = { 'type': '2', 
                                'year': str(y), 
                                'quarter': str(q), 
                                'limit': '1'}
                                response = requests.get(url, headers=headers, params=params) # G·ª≠i y√™u c·∫ßu GET
                                if response.status_code == 200:
                                    data = response.json() # ƒë·ªïi th√†nh object trong python
                                    if not data:
                                        continue
                                    resp_json = json.dumps(data, ensure_ascii=False) # Chuy·ªÉn object th√†nh chu·ªói JSON
                                    conn.execute(query, {"ticker": co_phieu, "year": y, "quarter": q, "data": resp_json}) # Th·ª±c thi c√¢u l·ªánh ch√®n d·ªØ li·ªáu
                                time.sleep(1) # Th·ªùi gian ch·ªù gi·ªØa c√°c y√™u c·∫ßu ƒë·ªÉ tr√°nh b·ªã ch·∫∑n
                        print(f'x·ª≠ l√Ω xong cho {co_phieu}')
                        transaction.commit()
                    except Exception as e:
                        transaction.rollback()
                        print(f"Error: {e}")
                        traceback.print_exc()
        except Exception as e:
            print(f"Failed to process {ticker}: {e}")
            traceback.print_exc()

# H√†m c·∫≠p nh·∫≠t d·ªØ li·ªáu gi√° c·ªï phi·∫øu h√†ng ng√†y v·ªõi c∆° ch·∫ø th√¥ng minh (smart catch-up)
def daily_catchup_update(engine):
    print("--- üîÑ CH·∫†Y C·∫¨P NH·∫¨T TH√îNG MINH (SMART CATCH-UP) ---")
    header = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36',
        'Authorization': 'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IkdYdExONzViZlZQakdvNERWdjV4QkRITHpnSSIsImtpZCI6IkdYdExONzViZlZQakdvNERWdjV4QkRITHpnSSJ9.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmZpcmVhbnQudm4iLCJhdWQiOiJodHRwczovL2FjY291bnRzLmZpcmVhbnQudm4vcmVzb3VyY2VzIiwiZXhwIjoxODg5NjIyNTMwLCJuYmYiOjE1ODk2MjI1MzAsImNsaWVudF9pZCI6ImZpcmVhbnQudHJhZGVzdGF0aW9uIiwic2NvcGUiOlsiYWNhZGVteS1yZWFkIiwiYWNhZGVteS13cml0ZSIsImFjY291bnRzLXJlYWQiLCJhY2NvdW50cy13cml0ZSIsImJsb2ctcmVhZCIsImNvbXBhbmllcy1yZWFkIiwiZmluYW5jZS1yZWFkIiwiaW5kaXZpZHVhbHMtcmVhZCIsImludmVzdG9wZWRpYS1yZWFkIiwib3JkZXJzLXJlYWQiLCJvcmRlcnMtd3JpdGUiLCJwb3N0cy1yZWFkIiwicG9zdHMtd3JpdGUiLCJzZWFyY2giLCJzeW1ib2xzLXJlYWQiLCJ1c2VyLWRhdGEtcmVhZCIsInVzZXItZGF0YS13cml0ZSIsInVzZXJzLXJlYWQiXSwianRpIjoiMjYxYTZhYWQ2MTQ5Njk1ZmJiYzcwODM5MjM0Njc1NWQifQ.dA5-HVzWv-BRfEiAd24uNBiBxASO-PAyWeWESovZm_hj4aXMAZA1-bWNZeXt88dqogo18AwpDQ-h6gefLPdZSFrG5umC1dVWaeYvUnGm62g4XS29fj6p01dhKNNqrsu5KrhnhdnKYVv9VdmbmqDfWR8wDgglk5cJFqalzq6dJWJInFQEPmUs9BW_Zs8tQDn-i5r4tYq2U8vCdqptXoM7YgPllXaPVDeccC9QNu2Xlp9WUvoROzoQXg25lFub1IYkTrM66gJ6t9fJRZToewCt495WNEOQFa_rwLCZ1QwzvL0iYkONHS_jZ0BOhBCdW9dWSawD6iF1SIQaFROvMDH1rg'
    }
    
    with engine.connect() as conn:
        transaction = conn.begin()
        # 1. T√¨m ng√†y m·ªõi nh·∫•t ƒëang c√≥ trong kho
        start_date = conn.execute(text('SELECT MAX("date") FROM raw.daily_price_history')).scalar()

        if start_date is None:
            print("‚ö†Ô∏è Kho tr·ªëng! Vui l√≤ng ch·∫°y t·∫£i d·ªØ li·ªáu ƒë·∫ßy ƒë·ªß ban ƒë·∫ßu tr∆∞·ªõc khi ch·∫°y c·∫≠p nh·∫≠t th√¥ng minh.")
            return
        # 2. T√≠nh to√°n kho·∫£ng th·ªùi gian c·∫ßn b√π
        end_date = datetime.now().date()
        if start_date == end_date: 
            print("‚úÖ D·ªØ li·ªáu ƒë√£ m·ªõi nh·∫•t.")
            return

        if start_date < end_date:
            sql_upsert = text("""
            INSERT INTO raw.daily_price_history ("Ticker", open, high, close, volume, date)
            VALUES (:ticker, :open, :high, :close, :volume, :date)
            ON CONFLICT ("Ticker", "date") 
            DO UPDATE SET open = EXCLUDED.open, high = EXCLUDED.high, close = EXCLUDED.close, volume = EXCLUDED.volume
                              """)
            # 3. L·∫•y danh s√°ch ticker t·ª´ b·∫£ng companies_list
            df_tickers = pd.read_sql('SELECT "Ticker" FROM analysis_data.companies_list', engine)
            ticker_list = set(df_tickers['Ticker'].str.strip())
            # 4. L·∫∑p qua t·ª´ng ticker v√† t·∫£i d·ªØ li·ªáu c·∫ßn b√π
            for i,ticker in enumerate(ticker_list):
                print(f"‚è≥ [{i+1}/{len(ticker_list)}] ƒêang c·∫≠p nh·∫≠t {ticker} t·ª´ {start_date} ƒë·∫øn {end_date}...")
                # G·ªçi API ƒë·ªÉ l·∫•y d·ªØ li·ªáu t·ª´ start_date ƒë·∫øn end_date
                api_url = f"https://restv2.fireant.vn/symbols/{ticker}/historical-quotes?startDate={start_date}&endDate={end_date}&offset=0&limit=30"
                params = {'startDate': start_date, 'endDate': end_date, 'offset': 0, 'limit': 30}
                response = requests.get(api_url, headers=header, params=params)
                if response.status_code == 200:
                    data = response.json()
                    for record in data:
                        date = record.get('date').split('T')[0]  # L·∫•y ph·∫ßn ng√†y, b·ªè ph·∫ßn th·ªùi gian
                         # Ch√®n ho·∫∑c c·∫≠p nh·∫≠t d·ªØ li·ªáu v√†o b·∫£ng daily_price_history
                        conn.execute(sql_upsert, {
                            'ticker': ticker,
                            'open': record.get('priceOpen'),
                            'high': record.get('priceHigh'),
                            'close': record.get('priceClose'),
                            'volume': record.get('volume'),
                            'date': date
                        })
                        time.sleep(0.2)  # Gi·ªØ rate limit
                time.sleep(0.3)  # Gi·ªØ rate limit gi·ªØa c√°c ticker
        transaction.commit()   
        
        
# if __name__ == "__main__":
    # update_balance_raw(engine)
    # update_income_raw(engine)
    # update_cashflow_raw(engine)
    # update_ratio_raw(engine)